{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e72d525f-54c1-4efc-81d6-666b469e53c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d368b771-b467-4d26-95ce-14db96cc71b5",
   "metadata": {},
   "source": [
    "### Text reading line by line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc0fda34-ea67-4322-bc9a-6c3ceb37dfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_dict = {'yelp':   'data/sentiment_analysis/yelp_labelled.txt',\n",
    "                 'amazon': 'data/sentiment_analysis/amazon_cells_labelled.txt',\n",
    "                 'imdb':   'data/sentiment_analysis/imdb_labelled.txt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc7f004a-0bb9-4dee-ab47-26167623ba19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for source, filepath in filepath_dict.items():\n",
    "    df = pd.read_csv(filepath, names=['sentence', 'review'], sep='\\t')\n",
    "    df['source']=source\n",
    "    df_list.append(df)\n",
    "df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b0084a0-9db9-4920-adc2-81ca69742ada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>review</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  review source\n",
       "0                           Wow... Loved this place.       1   yelp\n",
       "1                                 Crust is not good.       0   yelp\n",
       "2          Not tasty and the texture was just nasty.       0   yelp\n",
       "3  Stopped by during the late May bank holiday of...       1   yelp\n",
       "4  The selection on the menu was great and so wer...       1   yelp"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44d719a9-ebf8-4690-8aef-ea900cf5b42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence    The selection on the menu was great and so wer...\n",
       "review                                                      1\n",
       "source                                                   yelp\n",
       "Name: 4, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfec6b8-42af-4ff5-96e7-5736322b8bcf",
   "metadata": {},
   "source": [
    "## Sklearn for reading sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66b984b9-f75d-4715-b11c-755104bb48de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0fbe171-c756-43db-8b11-7dea6be9339a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['John likes ice cream', 'John hates chocolate.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d109e39-ad6d-42a4-896e-19324c2c36fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'John': 0, 'likes': 5, 'ice': 4, 'cream': 2, 'hates': 3, 'chocolate': 1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=0, lowercase=False)\n",
    "vectorizer.fit(sentences)\n",
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940708e3-2ef1-4472-91f5-f6c5ebc0203e",
   "metadata": {},
   "source": [
    "#### ***`Note : vectorizer take each word and put in dectionary`***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "165ee6a1-0014-4758-8642-1523500afe57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0, 1, 1],\n",
       "       [1, 1, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(sentences).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf7be4da-f3d8-4689-a79b-cff4f2560849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test= ['hello world John and no one','cream with chocolate']\n",
    "vectorizer.transform(test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491f9511-4cd1-43cb-8d2c-36849780b88b",
   "metadata": {},
   "source": [
    "#### ***`Note:: transform() >> toarray() --> return 1 if find the word inside transform , or 0 if not then store it to an array`***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a64f285-272f-4042-88ff-1048dd4c7820",
   "metadata": {},
   "source": [
    "## Defining a Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b664c5b9-ebe2-4987-9cb1-b6e1e758c650",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d261bbf-3b47-42db-bbc7-23d3fd17e33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp = df[df['source'] == 'yelp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd6fbca4-f753-4b2c-9c34-b0701e5d68d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = df_yelp['sentence'].values\n",
    "review = df_yelp['review'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2433163f-294d-4844-aaf1-d71e25c258c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, review, test_size=0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3417daaf-5400-49a2-824c-a71fcc8d8c17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<750x1714 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7368 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(sentences_train)\n",
    "\n",
    "X_train = vectorizer.transform(sentences_train)\n",
    "X_test  = vectorizer.transform(sentences_test)\n",
    "X_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4a81a2-a930-4f80-9d5f-464a968889a1",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef52b39f-b09d-42b4-beec-20d86fc7d4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77610174-f324-4ba8-ba68-6a5d756f53f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.796\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "score = classifier.score(X_test, y_test)\n",
    "print(\"Accuracy:\", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ac1f660-1dcd-424e-a7bd-24be7580365d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for yelp data: 0.7960\n",
      "Accuracy for amazon data: 0.7960\n",
      "Accuracy for imdb data: 0.7487\n"
     ]
    }
   ],
   "source": [
    "for source in df['source'].unique():\n",
    "    df_source = df[df['source'] == source]\n",
    "    sentences = df_source['sentence'].values\n",
    "    y = df_source['review'].values\n",
    "\n",
    "    sentences_train, sentences_test, y_train, y_test = train_test_split(\n",
    "        sentences, y, test_size=0.25, random_state=1000)\n",
    "\n",
    "    vectorizer = CountVectorizer()\n",
    "    vectorizer.fit(sentences_train)\n",
    "    X_train = vectorizer.transform(sentences_train)\n",
    "    X_test  = vectorizer.transform(sentences_test)\n",
    "\n",
    "    classifier = LogisticRegression()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    score = classifier.score(X_test, y_test)\n",
    "    print('Accuracy for {} data: {:.4f}'.format(source, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7cad12-f00a-4ba3-bc6c-80fae281617e",
   "metadata": {},
   "source": [
    "#### ***`Note:: use unique() to take only unique value without repeated`***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
